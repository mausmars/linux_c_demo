https://zhuanlan.zhihu.com/p/352537447

高速缓存中的数据写回主存并非立即执行，写回主存的时机：
1.缓存满了，采用先进先出或最久未使用的顺序写回；
2.#Lock信号，缓存一致性协议，明确要求数据计算完成后要立马同步回主存。

-----------------------------
多级缓存结构
L1，L2和L3

L1高速缓存是系统中存在的最快的内存。
256KB 1-2MB

L2级缓存比L1慢，但大小更大
256KB 8MB

L3级高速缓存是最大的高速存储单元，也是最慢的
4MB 50MB

-----------------------------
多处理器缓存结构
一个处理器对应一个物理插槽，包含多个核多个核（一个核包含寄存器、L1 Cache、L2 Cache），多核间共享L3 Cache，多处理器间通过QPI总线相连。
L3缓存包括了在同一个槽上的所有L1和L2缓存中的数据


Cache Line
Cache存储数据以固定大小为单位，称为Cache Line/Block。给定容量和Cache Line size，则就固定了存储的条目个数
对于X86，Cache Line大小与DDR一次访存能得到的数据大小一致，即64B

CPU从Cache获取数据的最小单位为字节
Cache从Memory获取的最小单位是Cache Line
Memory从磁盘获取数据通常最小是4K

Cache分成多个组，每组分成多个Cache Line行


Linux系统下使用以下命令查看Cache信息，lscpu 命令也可。
ls /sys/devices/system/cpu/cpu0/cache/index0

-----------------------------
缓存的存取与一致
存取速度：寄存器 > cache(L1~L3) > RAM > Flash > 硬盘 > 网络存储
寄存器   1周期        1ns
l1      4-5周期      2-2.5ns  64k
l2      12          6ns      1m
l3      30          15ns     35.75m
内存     100         50ns     G
以2.2Ghz频率的CPU为例，每个时钟周期大概是0.5纳秒。

读取存储器数据
1) 如CPU要读的数据在L1 cache，锁住cache行，读取后解锁、返回
2) 如CPU要读的数据在L2 cache，数据在L2里加锁，将数据复制到L1，再执行读L1
3) 如CPU要读的数据在L3 cache，也一样，只不过先由L3复制到L2，再从L2复制到L1，最后从L1到CPU
4) 如CPU需读取内存，则首先通知内存控制器占用总线带宽，后内存加锁、发起读请求、等待回应，回应数据保存至L3，L2,L1，再从L1到CPU后解除总线锁定。

缓存命中与延迟
L1里命中的概率大概在80%左右，L2、L3的机制也类似
CPU需要在主存中读取的数据大概为5%-10%，其余命中全部可以在L1、L2、L3中获取，大大减少了系统的响应时间。

缓存替换策略
Cache里的数据是Memory中常用数据的一个拷贝，存满后再存入一个新的条目时，就需要把一个旧的条目从缓存中拿掉，这个过程称为evict。
最简单的策略为LRU

MESI缓存一致性
假设一个变量在CPU0和CPU1的本地Cache中都有一份拷贝，当CPU0修改了这个变量时，就必须以某种方式通知CPU1，以便CPU1能够及时更新自己本地Cache中的拷贝，这样才能在两个CPU之间保持数据的同步，CPU之间的这种同步有较大开销。

MESI：Modified Exclusive Shared or Invalid
1) 协议中的状态
CPU中每个缓存行使用4种状态进行标记(使用额外的两位bit表示)
M: Modified
该缓存行只被缓存在该CPU的缓存中，且被修改过(dirty),即与主存中的数据不一致，该缓存行中的内容需在未来的某个时间点(允许其它CPU读取主存中相应内存之前)写回主存。当被写回主存之后，该缓存行的状态变成独享(exclusive)状态
E: Exclusive
该缓存行只被缓存在该CPU的缓存中，未被修改，与主存中数据一致。在任何时刻当有其它CPU读取该内存时变成shared状态。同样，当修改该缓存行中内容时，该状态可以变成Modified状态.
S: Shared
意味该缓存行可能被多个CPU缓存，各个缓存中的数据与主存数据一致，当有一个CPU修改该缓存行中，其它CPU中该缓存行可以被作废(Invalid).
I: Invalid，缓存无效(可能其它CPU修改了该缓存行)

状态切换关系

缓存的操作描述

代码设计的考量
时间局部性
如果一个数据/信息项被访问过一次，那么很有可能它会在很短的时间内再次被访问。比如循环、递归、方法的反复调用等。

空间局部性
一个Cache Line有64字节块，可以充分利用一次加载64字节的空间，把程序后续会访问的数据，一次性全部加载进来，从而提高Cache Line命中率（而非重新去寻址读取）。
如果一个数据被访问，那么很有可能位于这个数据附近的其它数据也会很快被访问到。比如顺序执行的代码、连续创建的多个对象、数组等。数组就是一种把局部性原理利用到极致的数据结构。

参看cpu_cache_test例子
数组元素存储在地址连续的内存中，多维数组在内存中是按行进行存储。第一个程序按行访问某个元素时，该元素附近的一个Cache Line大小的元素都会被加载到Cache中，这样一来，在访问紧挨着的下一个元素时，
就可直接访问Cache中的数据，不需再从内存中加载。也就是说，对数组按行进行访问时，具有更好的空间局部性，Cache命中率更高。


伪共享的规避
伪共享(False Sharing） 由于运行在不同CPU上的不同线程，同时修改处在同一个Cache Line上的数据引起。缓存行上的写竞争是运行在SMP系统中并行线程实现可伸缩性最重要的限制因素，一般来说，从代码中很难看清是否会出现伪共享
会导致大量的Cache miss，因而造成程序性能的大幅下降

规避处理方式
1.增大数组元素的间隔使得不同线程存取的元素位于不同cache line，空间换时间
2.在每个线程中创建全局数组各个元素的本地拷贝，然后结束后再写回全局数组

有效的 Padding 方式 参看padding_test
-----------------------
缓存与内存对齐

字节对齐的细节和编译器实现相关，但一般而言，满足三个准则：
(结构体)变量的首地址能够被其(最宽)基本类型成员的大小所整除；
结构体每个成员相对于首地址的偏移量都是成员大小的数倍，如有需要,编译器会在成员之间加上填充字节(internal adding)
结构体的总大小为结构体最宽基本类型成员大小的数倍，如有需要,编译器会在最末一个成员之后加上填充字节(trailing padding)